---
layout: post
title: 'An√°lise da mem√≥ria da JVM em um container Docker'
date: 2021-01-02 12:18:00 -03:00
categories:
- jvm
tags:
- docker
- openshift
- kubernetes
- openjdk
author-id: mhagnumdw
image: "assets/img/posts/memoria-jvm-container-docker/banner.jpg"
feature-img: "assets/img/posts/memoria-jvm-container-docker/banner.jpg"
thumbnail: "assets/img/posts/memoria-jvm-container-docker/banner.jpg"
---

An√°lise da mem√≥ria da JVM... // TODO: escrever mais

<!--more-->

- [In√≠cio](#in√≠cio)
- [Rela√ß√£o entre o `Xmx` (`MaxHeapSize`) e a mem√≥ria f√≠sica total](#rela√ß√£o-entre-o-xmx-maxheapsize-e-a-mem√≥ria-f√≠sica-total)
  - [JVM antiga que identifica de forma errada a mem√≥ria f√≠sica total ‚õî](#jvm-antiga-que-identifica-de-forma-errada-a-mem√≥ria-f√≠sica-total-)
  - [JVM que identifica de forma correta a mem√≥ria f√≠sica total üéâ](#jvm-que-identifica-de-forma-correta-a-mem√≥ria-f√≠sica-total-)
- [Alguns par√¢metros da JVM menos comuns](#alguns-par√¢metros-da-jvm-menos-comuns)
  - [-XX:MaxRAM](#-xxmaxram)
  - [-XX:+UseParallelGC](#-xxuseparallelgc)
  - [-XX:MinHeapFreeRatio=percent](#-xxminheapfreeratiopercent)
  - [-XX:MaxHeapFreeRatio=percent](#-xxmaxheapfreeratiopercent)
  - [-XX:GCTimeRatio=nnn](#-xxgctimerationnn)
  - [-XX:AdaptiveSizePolicyWeight=nn](#-xxadaptivesizepolicyweightnn)
- [For√ßando a jvm a devolver mem√≥ria para o SO](#for√ßando-a-jvm-a-devolver-mem√≥ria-para-o-so)
- [V√°rias JVM dentro de um container](#v√°rias-jvm-dentro-de-um-container)
- [Ajustando os par√¢metros da JVM](#ajustando-os-par√¢metros-da-jvm)
  - [Sobre oa par√¢metros da JVM utilizados nos testes](#sobre-oa-par√¢metros-da-jvm-utilizados-nos-testes)
  - [Sobre o log do GC](#sobre-o-log-do-gc)
  - [Verificando o tempo do GC - Exemplo 1](#verificando-o-tempo-do-gc---exemplo-1)
  - [Verificando o tempo do GC - Exemplo 2](#verificando-o-tempo-do-gc---exemplo-2)
- [Executando os testes de carga](#executando-os-testes-de-carga)
  - [Interface gr√°fica (JMeter GUI)](#interface-gr√°fica-jmeter-gui)
  - [Linha de comando (JMeter)](#linha-de-comando-jmeter)
  - [Linha de comando (Jmeter com Taurus)](#linha-de-comando-jmeter-com-taurus)
- [// TODO: Falar dessas coisas?](#-todo-falar-dessas-coisas)
- [Refer√™ncias](#refer√™ncias)

## In√≠cio

**// TODO:** Tudo o que for dito aqui √© valido para a OpenJDK, ok? Vers√£o 1.8.0_212 acima, ok?

**// TODO:** renomear de HEAP para `HEAP`

**// TODO:** usar a sigla SO ou o termo Sistema Operacional?

However, as a starting point for running OpenJDK in a container, at least the following three memory-related tasks are key:

- Overriding the JVM maximum heap size.
- Encouraging the JVM to release unused memory to the operating system, if appropriate.
- Ensuring all JVM processes within a container are appropriately configured.

## Rela√ß√£o entre o `Xmx` (`MaxHeapSize`) e a mem√≥ria f√≠sica total

Por padr√£o, se o `Xmx` (`MaxHeapSize`) n√£o for definido, o seu valor m√°ximo ser√° **1/4** da mem√≥ria f√≠sica total. Esse **1/4** √© definido pelo par√¢metro `MaxRAMFraction` e pode ser alterado.

**Para observar isso:**

- verificar a mem√≥ria f√≠sica total com o comando `free -m` (se a execu√ß√£o for dentro de um container docker, deve-se tomar como mem√≥ria f√≠sica total a mem√≥ria alocada para o container)
- obter o `MaxRAMFraction` e `MaxHeapSize` da jvm, com o comando `java -XX:+PrintFlagsFinal -version | grep -iE 'HeapSize|PermSize|ThreadStackSize|MaxRAMFraction'`
- ent√£o verificar que se o `MaxRAMFraction` for **4**, o `MaxHeapSize` ser√° **1/4** da mem√≥ria f√≠sica total

Abaixo uma ilustra√ß√£o do que foi dito acima:

![MaxRAMFraction vs MaxHeapSize vs Mem√≥ria F√≠sica Total]({{ site.baseurl }}/assets/img/posts/memoria-jvm-container-docker/MaxRAMFraction-e-MaxHeapSize-vs-Memoria-Fisica-Total.png)

> üìã ATEN√á√ÉO
>
> - üëÄ O comando `free -m` dentro de um container vai reportar a mem√≥ria do host e n√£o do container. O c√°lculo acima, no caso de um container, deve levar em considera√ß√£o como mem√≥ria f√≠sica a mem√≥ria alocada para o container.
> - üêû A jvm, em vers√µes anteriores a **`// TODO: XXXXXXXXXXXXXXXXXX`**, s√≥ identifica a mem√≥ria do host e n√£o do container. Isso √© um bug.
> - üòé √â poss√≠vel verificar a mem√≥ria f√≠sica total de um container por meio do arquivo `cat /sys/fs/cgroup/memory/memory.limit_in_bytes` (para outros par√¢metros ver [aqui](https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt))

### JVM antiga que identifica de forma errada a mem√≥ria f√≠sica total ‚õî

Aqui vamos apenas demonstrar esse problema. Verificando a mem√≥ria do host:

```console
$ free -m # valores em MB
              total        used        free      shared  buff/cache   available
Mem:          12549        3236         266         274        9046        8773
Swap:          4096           2        4094
```

Alocando **1GB** de mem√≥ria f√≠sica para o container docker da jvm:

```console
$ docker run -it --rm \
  --memory $(( 1 * 1024 * 1024 * 1024 )) \
  openjdk:8u92-alpine \
  java -XX:+PrintFlagsFinal -version | grep -iE 'HeapSize|PermSize|ThreadStackSize|MaxRAMFraction'

     intx CompilerThreadStackSize                   = 0                                   {pd product}
    uintx DefaultMaxRAMFraction                     = 4                                   {product}
    uintx ErgoHeapSizeLimit                         = 0                                   {product}
    uintx HeapSizePerGCThread                       = 87241520                            {product}
    uintx InitialHeapSize                          := 207618048                           {product}
    uintx LargePageHeapSizeThreshold                = 134217728                           {product}
    uintx MaxHeapSize                              := 3290431488                          {product}
    uintx MaxRAMFraction                            = 4                                   {product}
     intx ThreadStackSize                           = 1024                                {pd product}
     intx VMThreadStackSize                         = 1024                                {pd product}
openjdk version "1.8.0_92-internal"
OpenJDK Runtime Environment (build 1.8.0_92-internal-alpine-r1-b14)
OpenJDK 64-Bit Server VM (build 25.92-b14, mixed mode)
```

Pelo resultado acima, o valor do `MaxHeapSize` √© `3138 MB` (`3290431488` bytes / 1024 / 1024).

**3138 MB √© 1/4 da mem√≥ria f√≠sica do host e n√£o da mem√≥ria f√≠sica do container.** Portanto a jvm identificou errado, isso √© um bug que foi corrigido a partir da vers√£o **`// TODO: XXXXXXXXXXXXXXXXXX`**.

> üìã NOTA
>
> - Observar que para o teste acima usamos a jdk 1.8.0_92. Imagem docker `openjdk:8u92-alpine`.
> - Esse problema √© facilmente contornado se o `Xmx` for explicitamente definido na linha de comando da jvm. O que eu pessoalmente acho uma boa pr√°tica.
> - Se por algum motivo n√£o se deseja definir o `Xmx`, basta informar para a jvm o total de mem√≥ria dispon√≠vel por meio do par√¢metro `-XX:MaxRAM`, ex: `-XX:MaxRAM=1G`.

### JVM que identifica de forma correta a mem√≥ria f√≠sica total üéâ

Agora, apenas para exemplificar o caso de sucesso. Verificando a mem√≥ria do host:

```console
$ free -m # valores em MB
              total        used        free      shared  buff/cache   available
Mem:          12549        3236         266         274        9046        8773
Swap:          4096           2        4094
```

Alocando **1GB** de mem√≥ria f√≠sica para o container docker da jvm:

```console
$ docker run -it --rm \
  --memory $(( 1 * 1024 * 1024 * 1024 )) \
  openjdk:8-jdk-alpine \
  java -XX:+PrintFlagsFinal -version | grep -iE 'HeapSize|PermSize|ThreadStackSize|MaxRAMFraction'

     intx CompilerThreadStackSize                   = 0                                   {pd product}
    uintx DefaultMaxRAMFraction                     = 4                                   {product}
    uintx ErgoHeapSizeLimit                         = 0                                   {product}
    uintx HeapSizePerGCThread                       = 87241520                            {product}
    uintx InitialHeapSize                          := 16777216                            {product}
    uintx LargePageHeapSizeThreshold                = 134217728                           {product}
    uintx MaxHeapSize                              := 268435456                           {product}
    uintx MaxRAMFraction                            = 4                                   {product}
     intx ThreadStackSize                           = 1024                                {pd product}
     intx VMThreadStackSize                         = 1024                                {pd product}
openjdk version "1.8.0_212"
OpenJDK Runtime Environment (IcedTea 3.12.0) (Alpine 8.212.04-r0)
OpenJDK 64-Bit Server VM (build 25.212-b04, mixed mode)
```

Pelo resultado acima, o valor do `MaxHeapSize` √© `256 MB` (`268435456` bytes / 1024 / 1024).

**256 MB √© exatamente 1/4 da mem√≥ria f√≠sica do container.** Portanto a jvm identificou corretamente.

> üìã NOTA
>
> - Observar que para o teste acima usamos a jdk 1.8.0_212. Imagem docker `openjdk:8-jdk-alpine`.
> - Pessoalmente eu acho uma boa pr√°tica definir o `Xmx` na linha de comando da jvm, ao inv√©s de deixar a jvm calcular.

## Alguns par√¢metros da JVM menos comuns

// TODO: escrever sobre esses par√¢metros em portugu√™s da forma mais clara poss√≠vel

### -XX:MaxRAM

Indica para a jvm o total de mem√≥ria f√≠sica dispon√≠vel. Exemplo para definir 1 GB: `-XX:MaxRAM=1G`.

### -XX:+UseParallelGC

_The parallel collector (also known as the throughput collector) performs minor collections in parallel, which can significantly reduce garbage collection overhead. It is intended for applications with medium-sized to large-sized data sets that are run on multiprocessor or multithreaded hardware. The parallel collector is selected by default on certain hardware and operating system configurations, or can be explicitly enabled with the option `-XX:+UseParallelGC`._

### -XX:MinHeapFreeRatio=percent

// TODO: escrever

### -XX:MaxHeapFreeRatio=percent

_Sets the maximum allowed percentage of free heap space (0 to 100) after a GC event. If free heap space expands above this value, then the heap will be shrunk. By default, this value is set to 70%. The following example shows how to set the maximum free heap ratio to 75%: `-XX:MaxHeapFreeRatio=75`_

### -XX:GCTimeRatio=nnn

_A hint to the virtual machine that it's desirable that not more than 1 / (1 + nnn) of the application execution time be spent in the collector. For example `-XX:GCTimeRatio=19` sets a goal of 5% of the total time for GC and throughput goal of 95%. That is, the application should get 19 times as much time as the collector. By default the value is 99, meaning the application should get at least 99 times as much time as the collector. That is, the collector should run for not more than 1% of the total time. This was selected as a good choice for server applications. A value that is too high will cause the size of the heap to grow to its maximum._

### -XX:AdaptiveSizePolicyWeight=nn

// TODO: escrever

## For√ßando a jvm a devolver mem√≥ria para o SO

> ü§îüí≠ Mas por qu√™?!

Em servidores dedicados, hosts f√≠sicos ou m√°quinas virtuais, √© comum e muitos locais recomendam, que em produ√ß√£o `Xms` (InitialHeapSize) e `Xmx` (MaxHeapSize) sejam iguais. Isso evita a jvm perder tempo alocando mem√≥ria e tamb√©m evita mais a frente precisar alocar e n√£o ter dispon√≠vel. No startup, com `Xms` e `Xmx` iguais, toda a mem√≥ria HEAP ser√° alocada pela jvm para que fique dispon√≠vel para a aplica√ß√£o.

Quando estamos em um ambiente compartilhado, com dezenas de containers rodando em um √∫nico host, orchestrados, por exemplo, por um `OpenShift` ou `Kubernetes`, queremos otimizar o uso de recursos ao m√°ximo, pois a mem√≥ria que um container est√° alocando e n√£o usando, poderia estar dispon√≠vel para outro container que realmente precise.

Outra ponto comum √© que a mem√≥ria HEAP da jvm em geral √© bem menor que a mem√≥ria f√≠sica total do servidor, ent√£o dificilmente a jvm vai usar mais mem√≥ria do que a dispon√≠vel no servidor.

Outra quest√£o √© que a mem√≥ria da jvm n√£o se resume a mem√≥ria HEAP, existem v√°rias outras √°reas de mem√≥ria chamadas _off-heap_ e elas tamb√©m consomem mem√≥ria do sistema operacional, sendo exemplos dessas √°reas: Metaspace, Thread Stack, Code Cache, Run-Time Constant Pool / Symbol, Native Method Stacks e Native Byte Buffers.

// TODO: rever o Metaspace citado logo acima, se algumas das √°reas de mem√≥rias j√° n√£o s√£o contidas nele

Uma forma de for√ßar a jvm a devolver (liberar) a mem√≥ria para o SO, √© com os par√¢metros abaixo:

```console
-XX:+UseParallelGC
-XX:MinHeapFreeRatio=5 -XX:MaxHeapFreeRatio=10 -XX:GCTimeRatio=4
-XX:AdaptiveSizePolicyWeight=90.
```

// TODO: explicar um pouco aqui ou informar que isso ser√° visto em detalhes mais a frente

## V√°rias JVM dentro de um container

N√£o √© comum, mas um container pode rodar mais de uma jvm full time (durante toda a vida do container), ou mesmo o processo principal da jvm pode disparar um processo tempor√°rio em outra jvm. Imagine que a aplica√ß√£o executa processos `maven`, aqui j√° temos ent√£o outra jvm concorrendo com a jvm principal. Se voc√™ est√° fazendo um _troubleshooting_ com aplicativos java de diagn√≥stico, como por exemplo `jps`, `jmap`, `jcmd`, todos eles rodam em uma jvm e logo estar√£o concorrendo em recursos com a jvm principal.

O ideal √© que esse outros processos java sejam iniciados com par√¢metros de mem√≥ria bem definidos. Fora explicitar os par√¢metros da jvm em cada chamada, uma forma de tentar garantir isso globalmente dentro do container, √© definindo valores padr√µes para processos java por meio da vari√°vel de ambiente `JAVA_TOOL_OPTIONS`. A OpenJDK e a Oracle JDK respeitam essa vari√°vel.

Uma forma de constatar isso √© iniciando um processo da jvm, em uma √∫nica linha de comando:

```console
$ docker run -it --rm \
  --env JAVA_TOOL_OPTIONS="-Xms6m -Xmx20m" \
  openjdk:8-jdk-alpine \
  java -XX:+PrintFlagsFinal -version | grep -iE 'InitialHeapSize|MaxHeapSize'

    uintx InitialHeapSize                          := 6291456                             {product}
    uintx MaxHeapSize                              := 20971520                            {product}
openjdk version "1.8.0_212"
OpenJDK Runtime Environment (IcedTea 3.12.0) (Alpine 8.212.04-r0)
OpenJDK 64-Bit Server VM (build 25.212-b04, mixed mode)

$ echo "InitialHeapSize: $(( 6291456 / 1024 / 1024 )) MB  /  MaxHeapSize: $(( 20971520 / 1024 / 1024 )) MB"
InitialHeapSize: 6 MB  /  MaxHeapSize: 20 MB
```

Ou podemos iniciar um container com o `sh` e executar os comandos dentro do container para constatar:

```console
# Iniciando o container docker sem qualquer par√¢metro
$ docker run -it --rm openjdk:8-jdk-alpine sh

# Aqui j√° estamos dentro do container, no shell

# Executando uma aplica√ß√£o java
/ # java -XX:+PrintFlagsFinal -version | grep -iE 'InitialHeapSize|MaxHeapSize'
    uintx InitialHeapSize                          := 207618048                           {product}
    uintx MaxHeapSize                              := 3290431488                          {product}
openjdk version "1.8.0_212"
OpenJDK Runtime Environment (IcedTea 3.12.0) (Alpine 8.212.04-r0)
OpenJDK 64-Bit Server VM (build 25.212-b04, mixed mode)

# Apenas exibindo os valores de Xms e Xmx obtidos (ver acima que n√£o definimos esses valores)
/ # echo "InitialHeapSize: $(( 207618048 / 1024 / 1024 )) MB  /  MaxHeapSize: $(( 3290431488 / 1024 / 1024 )) MB"
InitialHeapSize: 198 MB  /  MaxHeapSize: 3138 MB

# Agora vamos definir a env JAVA_TOOL_OPTIONS com os valores de Xms e Xmx
/ # export JAVA_TOOL_OPTIONS="-Xms6m -Xmx20m"

# Executando a aplica√ß√£o java novamente
/ # java -XX:+PrintFlagsFinal -version | grep -iE 'InitialHeapSize|MaxHeapSize'
Picked up JAVA_TOOL_OPTIONS: -Xms6m -Xmx20m
    uintx InitialHeapSize                          := 6291456                             {product}
    uintx MaxHeapSize                              := 20971520                            {product}
openjdk version "1.8.0_212"
OpenJDK Runtime Environment (IcedTea 3.12.0) (Alpine 8.212.04-r0)
OpenJDK 64-Bit Server VM (build 25.212-b04, mixed mode)

# E podemos ver que mesmo que o Xms e Xmx n√£o tenham sido definidos na linha de comando, os valores de
# Xms e Xms definidos na env JAVA_TOOL_OPTIONS foram respeitados
/ # echo "InitialHeapSize: $(( 6291456 / 1024 / 1024 )) MB  /  MaxHeapSize: $(( 20971520 / 1024 / 1024 )) MB"
InitialHeapSize: 6 MB  /  MaxHeapSize: 20 MB
```

// TODO: dividir a parte acima em blocos talvez melhore na visualiza√ß√£o

Vale ressaltar, que se uma aplica√ß√£o iniciar com valores definidos na linha de comando, esses ser√£o os valores efetivamente usados, e n√£o os valores definidos na vari√°vel de ambiente `JAVA_TOOL_OPTIONS`. Se `JAVA_TOOL_OPTIONS="-Xms6m -Xmx20m"` e a aplica√ß√£o inicia explicitando `-Xmx128m`, o `Xmx` efetivo ser√° `128m`.

> üìã Eu recomendo definir a vari√°vel de ambiente `JAVA_TOOL_OPTIONS`.

## Ajustando os par√¢metros da JVM

Mas n√£o vamos fazer √†s cegas. Vamos fazer testes pr√°ticos e mostrar com n√∫meros se os ajustes valem a pena ou n√£o.

GC paralelo, na configura√ß√£o padr√£o, a jvm vai tentar usar todo o heap. Isso acontece mesmo se a aplica√ß√£o precisar de pouco espa√ßo para executar. No GC serial isso √© minimizado, mas ainda assim ocorre.

Se a aplica√ß√£o precisa de bem menos mem√≥ria do que o HEAP m√°ximo configurado, o GC pode rodar antecipadamente, antes que o HEAP esteja quase todo em uso, liberando mem√≥ria para o SO. Isso pode ser configurado!

Muitas vezes a √∫nica instru√ß√£o que passamos para o GC √© o m√°ximo de HEAP que pode ser usado, n√£o informando, por exemplo, que menos HEAP (mem√≥ria) seja usado, e muito menos informamos como ele deve fazer isso.

Abaixo √© um exemplo de uma aplica√ß√£o em produ√ß√£o que est√° a 13 dias no ar, consumindo aproximadamente 380 MB da HEAP e ap√≥s um Full GC for√ßado cai para 122 MB, liberando 258 MB. A mem√≥ria s√≥ n√£o caiu mais porque a aplica√ß√£o estava com algumas tarefas em andamento no momento do GC. Em uma execu√ß√£o posterior for√ßada do GC a mem√≥ria caiu para 81 MB de uso.

> ‚ö†Ô∏è Um Full GC pode parar a sua apica√ß√£o por mil√©semos ou segundos! Cuidado!

<video muted autoplay controls style="width=:100%;padding: unset;">
    <source src="{{ site.baseurl }}/assets/img/posts/memoria-jvm-container-docker/heap-after-force-gc.mp4" type="video/mp4">
    Your browser does not support the video tag.
</video>

Como dito acima, √© poss√≠vel configurar a jvm para que menos HEAP seja usado, se poss√≠vel for, claro, liberando mem√≥ria para o SO, deixando o HEAP de um tamanho pr√≥ximo aos dados que a aplica√ß√£o efetivamente precisa no momento (ou seja, deixando em mem√≥ria apenas objetos ainda referenciados pela aplica√ß√£o/jvm).

Precisamos come√ßar definindo o `-Xms`, algo como `-Xms48M`. Isso varia com a aplica√ß√£o. Se a aplica√ß√£o inicialmente precisa de um m√≠nimo de **100 MB**, faz sentido definir algo como `-Xms128M`. Para uma necessidade inicial de **100 MB** pode-se definir `-Xms48M`, mas o GC s√≥ vai perder tempo alocando mais HEAP.

Outra op√ß√£o que temos √© aumentar a frequ√™ncia do GC, para que objetos mortos (n√£o mais referenciados) possam ser coletados e mem√≥ria possa ser liberada, mas de modo que isso adicione um custo baixo no processamento do GC para que n√£o impacte no funcionamento da aplica√ß√£o. Vale lembrar que as threads de limpeza do GC executam em paralelo com as threads da aplica√ß√£o.

Em servidores JBoss que tenho acesso, que recebem muitas requisi√ß√µes por dia, o tempo do GC fica abaixo de **1%** do tempo total de execu√ß√£o da JVM. Ent√£o se pudermos aumentar a frequ√™ncia do GC de modo que n√£o aumente muito esse tempo, estaremos removendo com mais frequ√™ncia objetos mortos e consequentemente menos mem√≥ria √© alocada (usada).

A JVM (Oracle JDK, OpenJDK, outras?) por padr√£o n√£o √© configurada para ser mais agressiva no GC porque inicialmente as aplica√ß√µes rodavam em servidores dedicados - inclusive √© o caso de algumas aplica√ß√µes enterprise que conhe√ßo, com todos os recursos voltados para a aplica√ß√£o, onde qualquer ganho de performance, embora √≠nfimo, era (ou √©!) levado em considera√ß√£o. Certamente alguns aplicativos, dependendo de como eles precisem usar a mem√≥ria, n√£o ir√£o se beneficiar de um GC mais agressivo, pelo contr√°rio, pode ser que a performance degrade muito devido a concorr√™ncia entre o GC (tentando limpar a mem√≥ria) e a aplica√ß√£o (tentando fazer o seu trabalho).

### Sobre oa par√¢metros da JVM utilizados nos testes

Para os testes vamos usar 4 configura√ß√µes de GC:

1. -XX:UseParallelGC
2. -XX:+UseSerialGC
3. -XX:+UseSerialGC -XX:MinHeapFreeRatio=20 -XX:MaxHeapFreeRatio=40
4. -XX:UseParallelGC -XX:MinHeapFreeRatio=20 -XX:MaxHeapFreeRatio=40 -XX:GCTimeRatio=4 -XX:AdaptiveSizePolicyWeight=90

`-XX:UseParallelGC` utiliza v√°rias threads para fazer a coleta de lixo, enquanto `-XX:+UseSerialGC` utiliza apenas uma thread.

O GC pode decidir por alocar mais HEAP ou mesmo liberar HEAP e isso pode ser controlado por meio dos par√¢metros `-XX:MinHeapFreeRatio` e `-XX:MaxHeapFreeRatio`, que recebem um valor inteiro em porcentagem.

- `-XX:MinHeapFreeRatio`: porcentagem m√≠nima de espa√ßo livre na HEAP (0 a 100%) **ap√≥s uma coleta do GC**. Se o tamanho do HEAP ficar menor que esse valor, o HEAP ser√° expandido. O valor padr√£o √© 40%. Exemplo: para um valor de 20% e HEAP com tamanho m√°ximo de 256 MB, o HEAP m√≠nimo alocado deve ser 51,2 MB. Se ap√≥s o GC o HEAP ficar em 40 MB, ele ser√° expandido para um valor acima de 51,2 MB.
- // TODO: acho que tanto o MinHeapFreeRatio (acima) e MaxHeapFreeRatio (abaixo), s√£o em rela√ß√£o ao espa√ßo livre da HEAP e n√£o em rela√ß√£o ao tamanho m√°ximo. Ser√°? Ver isso! Mas agora ao ler isso <https://www.openshift.com/blog/scaling-java-containers> mudei mais uma vez de ideia.
- `-XX:MaxHeapFreeRatio`: porcentagem m√°xima de espa√ßo livre na HEAP (0 a 100%) **ap√≥s uma coleta do GC**. Se o tamanho do HEAP ficar maior que esse valor, o HEAP ser√° reduzido. O valor padr√£o √© 70%. Exemplo: para um valor de 40% e HEAP com tamanho m√°ximo de 256 MB, o HEAP m√°ximo alocado deve ser 102,4 MB.

O GC paralelo (`-XX:UseParallelGC`) tenta equilibrar o custo de fazer a limpeza da mem√≥ria com o tempo gasto. Supondo uma mesma taxa de aloca√ß√£o de objetos, em um HEAP grande o GC acaba agindo menos, em um HEAP pequeno, como a mem√≥ria enche mais r√°pido, o GC precisa agir mais. √â poss√≠vel balancear esses dois pontos, custo do GC vs tempo para fazer a limpeza, por meio dos par√¢metros `-XX:GCTimeRatio` (padr√£o: 99) e `-XX:AdaptiveSizePolicyWeight` (padr√£o: 10 [0-100%]).

```bash
# visualizar o valor padr√£o
java -XX:+PrintFlagsFinal -version | grep -iE 'AdaptiveSizePolicyWeight|GCTimeRatio'

# ou para ver o valor de uma jvm j√° em execu√ß√£o
jcmd <JVM_PID> VM.flags -all | grep -iE 'AdaptiveSizePolicyWeight|GCTimeRatio'
```

- `-XX:GCTimeRatio`: √© uma dica para a jvm de que √© desej√°vel que n√£o mais que `1 / (1 + nnn)` do tempo de execu√ß√£o da jvm seja gasto com o GC. O valor padr√£o, 99, implica que o GC s√≥ pode tomar no m√°ximo **1%** (`1 / 1 + 99`) do tempo total de execu√ß√£o da jvm. Setando `-XX:GCTimeRatio` para, por exemplo, 4, teremos at√© 20% do tempo para o GC, ou seja, dedica mais tempo para limpeza do que para a redu√ß√£o de tempo de limpeza. Vale lembrar que esses 20% do tempo para o GC √© o pior caso, n√£o quer dizer que ele sempre usar√° 20% do tempo para fazer limpeza, isso at√© tornaria impratic√°vel o uso da aplica√ß√£o que "s√≥" teria 80% do tempo.
- `-XX:AdaptiveSizePolicyWeight`: indica quanto tempo das execu√ß√µes anteriores do GC devem ser levadas em considera√ß√£o para atingir a meta de tempo. O valor padr√£o, 10, indica que 90% das execu√ß√µes anteriores devem ser levadas em considera√ß√£o e apenas 10% deve levar em considera√ß√£o a execu√ß√£o atual. Supondo um valor 90 - ao inv√©s do padr√£o 10 - indica que a meta de tempo ser√° mais baseada na execu√ß√£o corrente do GC do que nas execu√ß√µes anteriores. Sup√µe-se que o GC corrente leva menos tempo que a soma dos anteriores, logo o GC fica mais longe da meta de tempo definida pelo `-XX:GCTimeRatio`, logo o GC acaba agindo mais.

### Sobre o log do GC

Para decidirmos qual das 4 op√ß√µes √© a melhor, ou melhor falando, √© a que mais se encaixa para a carga de trabalho a qual a aplica√ß√£o ser√° submetida, vamos analisar o log do GC. √â poss√≠vel atachar na JVM um programa (um jar) que se conecta direto ao GC por meio do [JVM Tool Interface/JVMTI](https://docs.oracle.com/javase/8/docs/platform/jvmti/jvmti.html), coletando dados direto do GC e fazendo an√°lise que for. N√£o vamos por essa op√ß√£o. Achei mais simples ativar o log de texto do GC, por meio do par√¢metro `-Xloggc:/path/to/gc.log` e um script `shell` simples que eu criei fazer a an√°lise. A desvantagem do log de texto √© que n√£o h√° um padr√£o para esse log entre as implementa√ß√µes de jvm. Ent√£o pode ser que esse script n√£o funcione em outra vers√£o/vendor de jvm.

// TODO: acima eu digo que usei o log do gc, mas s√≥ usei em partes, usei em conjunto o log do jstat -gc "$JVM_PID"


### Verificando o tempo do GC - Exemplo 1

// TODO: colocar aqui os tempos de GC do GRPFOR ou do ISS Fortaleza ap√≥s ficarem no ar por um longo tempo. Isso √© pra mostrar a raz√£o entre o tempo de GC e o tempo total da aplica√ß√£o.

### Verificando o tempo do GC - Exemplo 2

Outro exemplo, de um JBoss EAP 6.4, rodando a **108 dias**, mas com quase nada de carga nesse per√≠odo, apenas com os seguintes par√¢metros configurados referentes a mem√≥ria e GC: `-XX:PermSize=256m -XX:MaxPermSize=256m -Xms1024m -Xmx2048m`. Com um tempo de GC de **6974 segundos (~ 2h)**, o que representa apenas **0,0746%** do tempo total de execu√ß√£o da jvm. Abaixo como os dados desse exemplo foram coletados:

Obter o PID da JVM:

```bash
jps -lvm
# ou
ps aux | grep java
```

Vamos supor o PID 32549.

Obter o uptime da JVM em segundos:

```console
$ jcmd 32549 VM.uptime
32549:
9347114.094 s
```

Obter dados do GC da JVM (a coluna GCT significa _Garbage Collection Time_, em segundos):

```console
$ jstat -gc 32549
 S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT
25088,0 25088,0 23648,1  0,0   648704,0 182309,7 1398272,0  1255760,7  251504,0 231526,4 29608,0 24808,2  24832 6971,431   6      3,433 6974,864
```

Temos **6974 segundos**.

Descobrir quantos % do tempo o GC levou do tempo total de execu√ß√£o da JVM. Uma matem√°tica simples:

```console
$ bc <<< "scale=8; 6974 / 9347114 * 100"
.07461100
```

Temos **0.07461100%**. √â muito pouco!

> üßô‚Äç‚ôÇÔ∏è Em um comando s√≥:
>
> ```bash
> JVM_PID=32549; \
> GC_TOTAL_TIME=$( jstat -gc $JVM_PID | tail -n 1 | awk '{print $17}' | grep -P -o '^\d+' ); \
> JVM_UPTIME=$( jcmd $JVM_PID VM.uptime | tail -1 | grep -P -o '^\d+' ); \
> bc <<< "scale=8; $GC_TOTAL_TIME / $JVM_UPTIME * 100"
> ```

## Executando os testes de carga

Os testes de carga s√£o escritos no [JMeter](https://jmeter.apache.org/) e est√£o definidos no arquivo `jmeter.jmx`.

### Interface gr√°fica (JMeter GUI)

Os testes pode ser executados pela interface gr√°fica (GUI) do JMeter, **mas nesse caso apenas em tempo de desenvolvimento dos testes, pois a interface gr√°fica acaba consumindo recursos e concorrendo com o teste em si**. Para executar basta abrir o JMeter, menu `File > Open`, selecionar o arquivo `jmeter.jmx`, checar se os par√¢metros nos itens globais `User Defined Variables`, `HTTP Request Defaults` e `Grupo de Usu√°rios (Thread Group)` est√£o corretos, e por fim clicar no bot√£o `Start` (uma seta verde no formato de Play ‚ñ∂).

### Linha de comando (JMeter)

Os testes em sua execu√ß√£o valendo devem ser feitos via linha de comando, em uma m√°quina que esteja executando apenas os testes, sem qualquer outro processamento em paralelo que possa degradar a performance do teste. Para iniciar o teste basta executar:

```bash
jmeter -n -t jmeter.jmx
```

Se desejar ver um pouco mais de detalhes das requisi√ß√µes e da execu√ß√£o do JMeter, basta ativar o log de ambas, assim:

```bash
jmeter -n -t jmeter.jmx \
  -l /tmp/jmeter-requests.jtl -j /tmp/jmeter.log
```

Mais par√¢metros de linha de comando: <https://jmeter.apache.org/usermanual/get-started.html#non_gui>

### Linha de comando (Jmeter com [Taurus](https://gettaurus.org/))

Aqui temos uma interface bonita no console, que permite acompanhar os testes em tempo real.

```bash
docker run -it --rm \
  -v ~/projetos/jarvis:/bzt-configs \
  -v /tmp/jarvis-load-test-artifacts:/tmp/artifacts \
  blazemeter/taurus jmeter.jmx
```

> üìã NOTA
>
> - `~/projetos/jarvis` √© onde se encontra o `jmeter.jmx`
> - o volume `/tmp/jarvis-load-test-artifacts` √© opcional
> - em sistemas com SELinux √© preciso aplicar o contexto nas pastas dos volumes, ex: `sudo chcon -t svirt_sandbox_file_t /tmp/jarvis-load-test-artifacts`

## // TODO: Falar dessas coisas?

- que √© poss√≠vel obter os valores de limits e requests de mem√≥ria dentro do POD? <https://docs.openshift.com/container-platform/4.6/nodes/clusters/nodes-cluster-resource-configure.html#nodes-cluster-resource-configure-request-limit_nodes-cluster-resource-configure>**
- /sys/fs/cgroup/memory/memory.oom_control: <https://docs.openshift.com/container-platform/4.6/nodes/clusters/nodes-cluster-resource-configure.html#clipboard-8>
- containerStatuses do POD pra ver o √∫ltimo motivo do restart: <https://docs.openshift.com/container-platform/4.6/nodes/clusters/nodes-cluster-resource-configure.html#clipboard-17>

## Refer√™ncias

- Diversos par√¢metros da JVM: <https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html>
- `-XX:GCTimeRatio=nnn` e outros par√¢metros do GC: <https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gc-ergonomics.html>
- JVM + Configuring cluster memory to meet container memory and risk requirements: <https://docs.openshift.com/container-platform/4.6/nodes/clusters/nodes-cluster-resource-configure.html>
- Tuning Java's footprint in OpenShift (Part 1): <https://developers.redhat.com/blog/2014/07/15/dude-wheres-my-paas-memory-tuning-javas-footprint-in-openshift-part-1/>
- Tuning Java‚Äôs footprint in OpenShift (Part 2): <https://developers.redhat.com/blog/2014/07/22/dude-wheres-my-paas-memory-tuning-javas-footprint-in-openshift-part-2/>
- <https://www.baeldung.com/jvm-garbage-collectors>
- <https://www.baeldung.com/jvm-parameters>
- <https://www.blazemeter.com/blog/3-easy-ways-to-monitor-jmeter-non-gui-test-results>
